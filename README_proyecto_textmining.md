# Proyecto de Miner√≠a de Texto --- **Stock News Recommendation**

Este documento describe la estructura, prop√≥sito y flujo de ejecuci√≥n
del proyecto de miner√≠a de texto aplicado al an√°lisis de noticias
financieras (GDELT + RSS), incluyendo la construcci√≥n de matrices
TF--IDF, wordclouds, modelos LDA, CAR y GRF.

‚ö† **Importante:**\
Si ya cuentas con la base de datos descargada (`gdelt_apple.csv`),
**solo necesitas:**

1.  Cargar las librer√≠as\
2.  Ir directamente a la l√≠nea **235+** del script para leer la base y
    continuar el pipeline

Esto evita las **6--8 horas** de scraping completo.

------------------------------------------------------------------------

# üß∞ 0. Carga de Paquetes

``` r
require(pacman)
packages <- c(
  "tidyverse","lubridate","data.table","httr","jsonlite","stringi",
  "xml2","tidyquant","purrr","tidyRSS","text2vec","topicmodels",
  "tokenizers","stopwords","tidytext","SnowballC","grf","fixest",
  "tibble","cld3","rvest","wordcloud","Matrix","coop","tidyr",
  "stringr","patchwork","tm","textstem","maptpx","ranger"
)
lapply(packages, require, character.only = TRUE)
```

üëâ Si tienes el CSV, **salta a la l√≠nea 235**.

------------------------------------------------------------------------

# üì∞ 1. Descarga de Noticias RSS

Scraping de:

-   MarketWatch\
-   Nasdaq\
-   Yahoo Finance

Se extraen t√≠tulos, fechas, URL y cuerpos preliminares.

------------------------------------------------------------------------

# üåê 2. Descarga desde GDELT DOC API

Incluye:

-   Manejo de rangos de fechas\
-   Fix a JSON corruptos\
-   Scraping del cuerpo real\
-   Duraci√≥n: **6--8 horas**

Guardar base:

``` r
write.csv(gdelt_apple, ".../gdelt_apple.csv", row.names = FALSE)
```

------------------------------------------------------------------------

# üìÑ 3. Cargar Base Guardada

``` r
gdelt_apple <- read_csv(".../gdelt_apple.csv")
```

------------------------------------------------------------------------

# üßπ 4. Limpieza Avanzada del Texto

-   Eliminaci√≥n de copyright\
-   Detecci√≥n de idioma\
-   Eliminaci√≥n de newsletters\
-   Filtro de *market commentary*\
-   Remoci√≥n de s√≠mbolos y ruido

------------------------------------------------------------------------

# üß† 5. Normalizaci√≥n Sem√°ntica

Diccionario financiero:

-   stock, shares ‚Üí stock\
-   earnings, profit ‚Üí profit\
-   fall, drop ‚Üí fall

``` r
body_fixed <- normalize_financial_terms(body_fixed)
```

------------------------------------------------------------------------

# üçé Filtrado de Noticias Relevantes de Apple

``` r
gdelt_apple_only <- subset(
  gdelt_apple_clean,
  grepl(pattern, body_fixed, ignore.case = TRUE)
)
```

------------------------------------------------------------------------

# üî§ 6. Tokenizaci√≥n y Stemming

Pipeline:

1.  Tokenizaci√≥n\
2.  Stopwords\
3.  N√∫meros y tokens cortos\
4.  Stemming\
5.  Reconstrucci√≥n del texto limpio

------------------------------------------------------------------------

# üìä 7. An√°lisis Exploratorio

-   Wordcloud\
-   Frecuencia por proveedor\
-   Series de tiempo\
-   Distribuciones

Guardados en `/outcomes/`.

------------------------------------------------------------------------

# üßÆ 8. Matriz TF--IDF

1.  Conteo de t√©rminos\
2.  DF\
3.  Filtrado ‚â•5%\
4.  Matriz dispersa\
5.  Similitud del coseno

------------------------------------------------------------------------

# üìö 9. Modelos

-   CAR\
-   GRF\
-   Clasificaci√≥n UP/DOWN

------------------------------------------------------------------------

# ‚úî Recomendaci√≥n de Ejecuci√≥n

  Tarea                 Ejecutar   Comentario
  --------------------- ---------- ----------------------
  Cargar librer√≠as      ‚úî          Siempre
  Descargar RSS         Opcional   R√°pido
  Descargar GDELT       ‚ùå         Tarda 8 horas
  Cargar CSV            ‚úî          Iniciar en l√≠nea 235
  Procesamiento texto   ‚úî          Autom√°tico
  TF--IDF y modelos     ‚úî          Con base cargada

------------------------------------------------------------------------

# üë®‚Äçüíª Autor

Proyecto desarrollado para miner√≠a de texto aplicada al an√°lisis
financiero.
